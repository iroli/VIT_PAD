
**Задача 1. Очистка текста**  
Напишите функцию для предобработки текста. Функция должна:
- Приводить текст к нижнему регистру.
- Удалять лишние пробелы, знаки препинания и спецсимволы.
- Удалять цифровые значения.
- Токенизировать текст (разбивать на слова).
- Удалять стоп-слова на русском языке.

### Что такое очистка текста?


**Задача 2. Выделение ключевых слов с использованием TF-IDF**  
Реализуйте задание, в котором по очищенному корпусу текстов выделяются ключевые слова с помощью TF-IDF. Необходимо для каждого документа вывести топ-N слов по значимости.

### Что такое TF?
### Что такое IDF?
### Что такое TF-IDF?

**Задача 3. Тематическое моделирование с использованием LDA**  
На основе очищенного и токенизированного корпуса:
- Постройте словарь и матрицу «bag-of-words» с помощью gensim.
- Обучите модель LDA (например, выберите 3–5 тем).
- Выведите полученные темы, отобразив ключевые слова каждой темы.

### Что такое LDA? 
### Что эмбеддинги слов? предложения? текста? 



**Задача 3. Тематическое моделирование с использованием BERTTopic**  
На основе исходного корпуса:
- Обучите модель BERTTopic.
- Выведите информацию о полученных темах (например, таблицу с ключевыми словами каждой темы).

### Что такое тематическое моделирование?
### Чем BERTTopic от LDA отличается?
### Как оценить качество тематического разбиения?

**Задача 4. Оценка качества тем с использованием метрики когерентности**  
Рассчитайте метрику когерентности для тем, полученных с помощью BERTTopic

**Задача 4. Оценка когерентности тем (Coherence Score)**  
Рассчитайте метрику когерентности  для модели LDA. Объясните, что означает полученное значение.


**Задача 5. Генерация заголовков тем через LLM**  
Сформируйте текстовый prompt для генерации заголовка темы с помощью модели из HuggingFace (например, rugpt3small_based_on_gpt2 или аналогичной модели для русского языка).  
- Опишите, как составить prompt с ключевыми словами темы.
- Реализуйте функцию, которая принимает prompt и возвращает сгенерированный заголовок.

### Что такое трансформеры?
### кодировщик?
### Декодирвщик?
### Внимание?
### Самовнимание?

**Задача 5. 	NER**  
Используя pipeline от HuggingFace, реализуйте выделение именованных сущностей для одного из текстов корпуса (например, используя модель DeepPavlov для русского языка). Выведите найденные сущности с их типами и оценками уверенности.
+
